{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_INPUT_DATASET = \"House_Room_Dataset/Bedroom\"\n",
    "#Dataset link = https://www.kaggle.com/datasets/robinreni/house-rooms-image-dataset\n",
    "##kaggle datasets download -d robinreni/house-rooms-image-dataset — unzip\n",
    "\n",
    "TRAIN = \"training\"\n",
    "TEST = \"evaluation\"\n",
    "VAL = \"validation\"\n",
    "\n",
    "BASE_PATH = \"dataset\"\n",
    "BATCH_SIZE = 32\n",
    "CLASSES = [\"Modern\", \"Old\"] # \"Neutral\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist, metric):\n",
    "    if metric == 'auc_3':\n",
    "        plt.plot(hist.history[\"auc_3\"])\n",
    "        plt.plot(hist.history[\"val_auc_3\"])\n",
    "    else:\n",
    "        plt.plot(hist.history[\"loss\"])\n",
    "        plt.plot(hist.history[\"val_loss\"])\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.title(\"model {}\".format(metric))\n",
    "    plt.ylabel(\"{}\".format(metric))\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"labels.txt\", 'r') as f:\n",
    "    manual_labels = f.read()\n",
    "    \n",
    "labels = [i for i in manual_labels]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['O', 'M'])\n",
      "dict_values([271, 180])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(labels).keys()) \n",
    "print(Counter(labels).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(ORIG_INPUT_DATASET)\n",
    "files.sort(key=lambda f: int(f.split('_')[1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed_1.jpg', 'bed_2.jpg', 'bed_3.jpg', 'bed_4.jpg', 'bed_8.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will allocate ~ 75%, 15%, and 10% of the data for training, validation, and testing, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting files into train and test sets\n",
    "trainX, testX, trainY, testY =  train_test_split(files[:len(labels)], \n",
    "                 labels, \n",
    "                 stratify=labels, \n",
    "                 train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further splitting of train set into train and val sets\n",
    "trainX, valX, trainY, valY = train_test_split(trainX, trainY, stratify=trainY, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 344, 61, 61, 46, 46)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the size of train, test, eval\n",
    "len(trainX), len(trainY), len(valX), len(valY),  len(testX), len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over images in training folder: 100%|██████████| 344/344 [00:05<00:00, 68.28it/s]\n",
      "Iterating over images in evaluation folder: 100%|██████████| 46/46 [00:00<00:00, 71.61it/s]\n",
      "Iterating over images in validation folder: 100%|██████████| 61/61 [00:00<00:00, 63.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define configuration settings directly in the script\n",
    "BASE_PATH = \"House_Room_Dataset/Bedroom\"\n",
    "\n",
    "# Example data splits and labels\n",
    "splits = [(trainX, trainY), (testX, testY), (valX, valY)]\n",
    "dirnames = ['training', 'evaluation', 'validation']\n",
    "\n",
    "for i, (data, label) in enumerate(splits):\n",
    "    outside_dir = dirnames[i]\n",
    "\n",
    "    for j in tqdm(range(0, len(label)), desc=f\"Iterating over images in {outside_dir} folder\"):\n",
    "        dir = label[j]\n",
    "\n",
    "        # Construct the path to the sub-directory\n",
    "        dirPath = os.path.join(BASE_PATH, outside_dir, dir)\n",
    "\n",
    "        # If the output directory does not exist, create it\n",
    "        if not os.path.exists(dirPath):\n",
    "            os.makedirs(dirPath)\n",
    "\n",
    "        # Copy the image to this new directory\n",
    "        src_img = os.path.join(ORIG_INPUT_DATASET, data[j])\n",
    "        shutil.copy(src_img, dirPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 46 61\n"
     ]
    }
   ],
   "source": [
    "trainPath = os.path.join(BASE_PATH, TRAIN)\n",
    "valPath = os.path.join(BASE_PATH, VAL)\n",
    "testPath = os.path.join(BASE_PATH, TEST)\n",
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(valPath)))\n",
    "totalTest = len(list(paths.list_images(testPath)))\n",
    "print(totalTrain, totalTest, totalVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator(\n",
    "rotation_range=90,\n",
    "zoom_range=[0.5, 1.0],\n",
    "width_shift_range=0.3,\n",
    "height_shift_range=0.25,\n",
    "shear_range=0.15,\n",
    "horizontal_flip=True,\n",
    "fill_mode=\"nearest\",\n",
    "brightness_range=[0.2, 1.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create training batches whilst creating augmented images on the fly\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "directory=trainPath,\n",
    "target_size=(224,224),\n",
    "save_to_dir='dataset/augmented/train',\n",
    "save_prefix='train',\n",
    "shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create val batches \n",
    "valGen = valAug.flow_from_directory(\n",
    "directory=valPath,\n",
    "target_size=(224,224),\n",
    "shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create test batches\n",
    "testGen = testAug.flow_from_directory(\n",
    "directory=testPath,\n",
    "target_size=(224,224),\n",
    "shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel = EfficientNetB0(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False, # make sure top layer is not included\n",
    "            input_tensor=Input(shape=(224, 224, 3)),\n",
    "            pooling=\"avg\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the weights\n",
    "for layer in baseModel.layers:\n",
    "      layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a new classifier on top (Functional Keras Model)\n",
    "x = baseModel.output\n",
    "Layer_1 = BatchNormalization()(x)\n",
    "Layer_2 = Dropout(0.5)(Layer_1)\n",
    "output_layer = Dense(len(CLASSES), activation=\"softmax\")(Layer_2)\n",
    "model = Model(inputs = baseModel.input, outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to create the classifier on top of basemodel\n",
    "model = tf.keras.Sequential()\n",
    "model.add(baseModel)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(CLASSES), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=opt, \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[tf.keras.metrics.AUC()]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing early stopping\n",
    "es = EarlyStopping(\n",
    "     monitor='val_loss',  #metric to monitor\n",
    "     mode='min',  # whether to min or max the metric monitored\n",
    "     patience=10, # epochs to wait before declaring stopped training\n",
    "     verbose=1  # output epoch when training was stopped\n",
    "     )\n",
    "# implementing model checkpoint\n",
    "mc = ModelCheckpoint(\n",
    "      'feature_extraction.keras',\n",
    "       monitor='val_loss',\n",
    "       mode='min',\n",
    "       verbose=1, # display epoch+accuracy everytime model is saved\n",
    "       save_best_only=True\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('dataset/augmented/train', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67781, saving model to feature_extraction.keras\n",
      "10/10 - 66s - 7s/step - auc: 0.6137 - loss: 0.9065 - val_auc: 0.6502 - val_loss: 0.6778\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.67781 to 0.67619, saving model to feature_extraction.keras\n",
      "10/10 - 4s - 401ms/step - auc: 0.6221 - loss: 0.8692 - val_auc: 0.6595 - val_loss: 0.6762\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 3: val_loss improved from 0.67619 to 0.66095, saving model to feature_extraction.keras\n",
      "10/10 - 25s - 2s/step - auc: 0.6009 - loss: 0.8677 - val_auc: 0.6809 - val_loss: 0.6610\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 4: val_loss improved from 0.66095 to 0.65981, saving model to feature_extraction.keras\n",
      "10/10 - 3s - 344ms/step - auc: 0.7188 - loss: 0.7820 - val_auc: 0.6818 - val_loss: 0.6598\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 5: val_loss improved from 0.65981 to 0.65033, saving model to feature_extraction.keras\n",
      "10/10 - 25s - 2s/step - auc: 0.6846 - loss: 0.8008 - val_auc: 0.6915 - val_loss: 0.6503\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 6: val_loss improved from 0.65033 to 0.64943, saving model to feature_extraction.keras\n",
      "10/10 - 4s - 361ms/step - auc: 0.7852 - loss: 0.6590 - val_auc: 0.6936 - val_loss: 0.6494\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 7: val_loss improved from 0.64943 to 0.64161, saving model to feature_extraction.keras\n",
      "10/10 - 23s - 2s/step - auc: 0.7350 - loss: 0.7450 - val_auc: 0.7063 - val_loss: 0.6416\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 8: val_loss improved from 0.64161 to 0.64084, saving model to feature_extraction.keras\n",
      "10/10 - 4s - 399ms/step - auc: 0.7383 - loss: 0.7278 - val_auc: 0.7073 - val_loss: 0.6408\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 9: val_loss improved from 0.64084 to 0.63365, saving model to feature_extraction.keras\n",
      "10/10 - 29s - 3s/step - auc: 0.7075 - loss: 0.7617 - val_auc: 0.7232 - val_loss: 0.6337\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 10: val_loss improved from 0.63365 to 0.63314, saving model to feature_extraction.keras\n",
      "10/10 - 4s - 371ms/step - auc: 0.7275 - loss: 0.7681 - val_auc: 0.7266 - val_loss: 0.6331\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 11: val_loss improved from 0.63314 to 0.62684, saving model to feature_extraction.keras\n",
      "10/10 - 30s - 3s/step - auc: 0.7399 - loss: 0.7103 - val_auc: 0.7302 - val_loss: 0.6268\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 12: val_loss improved from 0.62684 to 0.62628, saving model to feature_extraction.keras\n",
      "10/10 - 4s - 429ms/step - auc: 0.9023 - loss: 0.5279 - val_auc: 0.7303 - val_loss: 0.6263\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 13: val_loss improved from 0.62628 to 0.62122, saving model to feature_extraction.keras\n",
      "10/10 - 24s - 2s/step - auc: 0.7645 - loss: 0.6920 - val_auc: 0.7279 - val_loss: 0.6212\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 14: val_loss improved from 0.62122 to 0.62084, saving model to feature_extraction.keras\n",
      "10/10 - 3s - 316ms/step - auc: 0.7422 - loss: 0.6916 - val_auc: 0.7292 - val_loss: 0.6208\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 15: val_loss improved from 0.62084 to 0.61743, saving model to feature_extraction.keras\n",
      "10/10 - 25s - 2s/step - auc: 0.7628 - loss: 0.6782 - val_auc: 0.7248 - val_loss: 0.6174\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 16: val_loss improved from 0.61743 to 0.61706, saving model to feature_extraction.keras\n",
      "10/10 - 4s - 433ms/step - auc: 0.6885 - loss: 0.8265 - val_auc: 0.7243 - val_loss: 0.6171\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 17: val_loss improved from 0.61706 to 0.61330, saving model to feature_extraction.keras\n",
      "10/10 - 41s - 4s/step - auc: 0.7719 - loss: 0.6612 - val_auc: 0.7270 - val_loss: 0.6133\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 18: val_loss improved from 0.61330 to 0.61275, saving model to feature_extraction.keras\n",
      "10/10 - 5s - 480ms/step - auc: 0.8574 - loss: 0.5078 - val_auc: 0.7272 - val_loss: 0.6128\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 19: val_loss improved from 0.61275 to 0.61179, saving model to feature_extraction.keras\n",
      "10/10 - 39s - 4s/step - auc: 0.7580 - loss: 0.6596 - val_auc: 0.7364 - val_loss: 0.6118\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 20: val_loss improved from 0.61179 to 0.61175, saving model to feature_extraction.keras\n",
      "10/10 - 3s - 305ms/step - auc: 0.7830 - loss: 0.5961 - val_auc: 0.7366 - val_loss: 0.6118\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.61175\n",
      "10/10 - 22s - 2s/step - auc: 0.7982 - loss: 0.6170 - val_auc: 0.7360 - val_loss: 0.6134\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.61175\n",
      "10/10 - 3s - 278ms/step - auc: 0.7998 - loss: 0.6318 - val_auc: 0.7354 - val_loss: 0.6136\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.61175\n",
      "10/10 - 22s - 2s/step - auc: 0.8065 - loss: 0.6102 - val_auc: 0.7206 - val_loss: 0.6136\n",
      "Epoch 24/25\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.61175\n",
      "10/10 - 3s - 288ms/step - auc: 0.7998 - loss: 0.5810 - val_auc: 0.7188 - val_loss: 0.6136\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.61175\n",
      "10/10 - 23s - 2s/step - auc: 0.7950 - loss: 0.6275 - val_auc: 0.7119 - val_loss: 0.6142\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "hist = model.fit(\n",
    "       x=trainGen,\n",
    "       epochs=25,\n",
    "       verbose=2,\n",
    "       validation_data=valGen,\n",
    "       steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "       callbacks=[es, mc]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8s/step\n",
      "No. of test images 46\n",
      "{'M': 0, 'O': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testGen.reset()\n",
    "predIdxs = model.predict(\n",
    "             x=testGen,\n",
    "             steps=(totalTest // BATCH_SIZE) + 1\n",
    "            )\n",
    "predIdxs = np.argmax(predIdxs, axis = 1)\n",
    "print(\"No. of test images\", len(predIdxs))\n",
    "print(testGen.class_indices)\n",
    "cm = confusion_matrix(testGen.classes, predIdxs)\n",
    "heatmap = sns.heatmap(cm, annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Functional name=efficientnetb0, built=True>: True\n",
      "<BatchNormalization name=batch_normalization_1, built=True>: True\n",
      "<Dropout name=dropout_1, built=True>: True\n",
      "<Dense name=dense_1, built=True>: True\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_model(model):\n",
    "     # unfreeze last conv block i.e. block7a \n",
    "     for layer in model.layers[-20:]:\n",
    "          if not isinstance(layer, BatchNormalization):\n",
    "               layer.trainable = True\n",
    "     # check which of these are trainable and which aren't\n",
    "     for layer in model.layers:\n",
    "          print(\"{}: {}\".format(layer, layer.trainable))\n",
    "     # compile (with an even smaller learning rate)\n",
    "     opt = Adam(learning_rate=1e-5)\n",
    "     model.compile(\n",
    "             optimizer=opt,\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=[tf.keras.metrics.AUC()]\n",
    "             )\n",
    "     return model\n",
    "model_fine_tuned = fine_tune_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen.reset()\n",
    "valGen.reset()\n",
    "testGen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61314, saving model to fine_tuned_house.keras\n",
      "10/10 - 60s - 6s/step - auc_1: 0.8042 - loss: 0.6180 - val_auc_1: 0.7143 - val_loss: 0.6131\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.61314 to 0.61300, saving model to fine_tuned_house.keras\n",
      "10/10 - 4s - 353ms/step - auc_1: 0.7256 - loss: 0.7110 - val_auc_1: 0.7143 - val_loss: 0.6130\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 3: val_loss improved from 0.61300 to 0.61204, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7963 - loss: 0.6151 - val_auc_1: 0.7157 - val_loss: 0.6120\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 4: val_loss improved from 0.61204 to 0.61194, saving model to fine_tuned_house.keras\n",
      "10/10 - 4s - 373ms/step - auc_1: 0.8887 - loss: 0.4533 - val_auc_1: 0.7170 - val_loss: 0.6119\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: val_loss improved from 0.61194 to 0.61102, saving model to fine_tuned_house.keras\n",
      "10/10 - 23s - 2s/step - auc_1: 0.8059 - loss: 0.6215 - val_auc_1: 0.7173 - val_loss: 0.6110\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 6: val_loss improved from 0.61102 to 0.61093, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 319ms/step - auc_1: 0.8984 - loss: 0.4500 - val_auc_1: 0.7170 - val_loss: 0.6109\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 7: val_loss improved from 0.61093 to 0.61016, saving model to fine_tuned_house.keras\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7772 - loss: 0.6303 - val_auc_1: 0.7184 - val_loss: 0.6102\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 8: val_loss improved from 0.61016 to 0.61005, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 320ms/step - auc_1: 0.7671 - loss: 0.6926 - val_auc_1: 0.7178 - val_loss: 0.6100\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 9: val_loss improved from 0.61005 to 0.60925, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7804 - loss: 0.6452 - val_auc_1: 0.7188 - val_loss: 0.6093\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 10: val_loss improved from 0.60925 to 0.60924, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 326ms/step - auc_1: 0.5801 - loss: 1.0027 - val_auc_1: 0.7180 - val_loss: 0.6092\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 11: val_loss improved from 0.60924 to 0.60852, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7617 - loss: 0.6730 - val_auc_1: 0.7216 - val_loss: 0.6085\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 12: val_loss improved from 0.60852 to 0.60846, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 330ms/step - auc_1: 0.8672 - loss: 0.4980 - val_auc_1: 0.7208 - val_loss: 0.6085\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: val_loss improved from 0.60846 to 0.60794, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7793 - loss: 0.6404 - val_auc_1: 0.7210 - val_loss: 0.6079\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: val_loss improved from 0.60794 to 0.60785, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 325ms/step - auc_1: 0.8770 - loss: 0.4952 - val_auc_1: 0.7216 - val_loss: 0.6079\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: val_loss improved from 0.60785 to 0.60724, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7982 - loss: 0.5972 - val_auc_1: 0.7216 - val_loss: 0.6072\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: val_loss improved from 0.60724 to 0.60718, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 324ms/step - auc_1: 0.7422 - loss: 0.7443 - val_auc_1: 0.7210 - val_loss: 0.6072\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 17: val_loss improved from 0.60718 to 0.60672, saving model to fine_tuned_house.keras\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7722 - loss: 0.6356 - val_auc_1: 0.7208 - val_loss: 0.6067\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: val_loss improved from 0.60672 to 0.60664, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 298ms/step - auc_1: 0.6667 - loss: 0.9326 - val_auc_1: 0.7216 - val_loss: 0.6066\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: val_loss improved from 0.60664 to 0.60634, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7445 - loss: 0.6861 - val_auc_1: 0.7227 - val_loss: 0.6063\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: val_loss improved from 0.60634 to 0.60625, saving model to fine_tuned_house.keras\n",
      "10/10 - 4s - 386ms/step - auc_1: 0.7197 - loss: 0.7375 - val_auc_1: 0.7218 - val_loss: 0.6063\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: val_loss improved from 0.60625 to 0.60610, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7765 - loss: 0.6610 - val_auc_1: 0.7216 - val_loss: 0.6061\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: val_loss improved from 0.60610 to 0.60609, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 329ms/step - auc_1: 0.9199 - loss: 0.4186 - val_auc_1: 0.7221 - val_loss: 0.6061\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: val_loss improved from 0.60609 to 0.60583, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.7721 - loss: 0.6456 - val_auc_1: 0.7233 - val_loss: 0.6058\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 24: val_loss improved from 0.60583 to 0.60581, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 326ms/step - auc_1: 0.9717 - loss: 0.3755 - val_auc_1: 0.7237 - val_loss: 0.6058\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.60581\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7992 - loss: 0.6155 - val_auc_1: 0.7267 - val_loss: 0.6059\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.60581\n",
      "10/10 - 3s - 279ms/step - auc_1: 0.7666 - loss: 0.6294 - val_auc_1: 0.7267 - val_loss: 0.6059\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 27: val_loss improved from 0.60581 to 0.60556, saving model to fine_tuned_house.keras\n",
      "10/10 - 24s - 2s/step - auc_1: 0.8207 - loss: 0.5865 - val_auc_1: 0.7278 - val_loss: 0.6056\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: val_loss improved from 0.60556 to 0.60553, saving model to fine_tuned_house.keras\n",
      "10/10 - 3s - 341ms/step - auc_1: 0.7432 - loss: 0.7075 - val_auc_1: 0.7278 - val_loss: 0.6055\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.8121 - loss: 0.6040 - val_auc_1: 0.7291 - val_loss: 0.6057\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 279ms/step - auc_1: 0.6709 - loss: 0.7363 - val_auc_1: 0.7286 - val_loss: 0.6057\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7849 - loss: 0.6491 - val_auc_1: 0.7294 - val_loss: 0.6056\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 279ms/step - auc_1: 0.8848 - loss: 0.4790 - val_auc_1: 0.7304 - val_loss: 0.6057\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.8166 - loss: 0.5886 - val_auc_1: 0.7294 - val_loss: 0.6061\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 278ms/step - auc_1: 0.7090 - loss: 0.7264 - val_auc_1: 0.7288 - val_loss: 0.6059\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7729 - loss: 0.6515 - val_auc_1: 0.7302 - val_loss: 0.6063\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 280ms/step - auc_1: 0.8594 - loss: 0.5207 - val_auc_1: 0.7292 - val_loss: 0.6063\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.8129 - loss: 0.5822 - val_auc_1: 0.7296 - val_loss: 0.6064\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 254ms/step - auc_1: 0.5955 - loss: 0.9648 - val_auc_1: 0.7299 - val_loss: 0.6064\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.8021 - loss: 0.6042 - val_auc_1: 0.7306 - val_loss: 0.6065\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 257ms/step - auc_1: 0.8715 - loss: 0.5050 - val_auc_1: 0.7317 - val_loss: 0.6065\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7931 - loss: 0.6306 - val_auc_1: 0.7294 - val_loss: 0.6068\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 280ms/step - auc_1: 0.6777 - loss: 0.7744 - val_auc_1: 0.7291 - val_loss: 0.6069\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7812 - loss: 0.6452 - val_auc_1: 0.7288 - val_loss: 0.6069\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 279ms/step - auc_1: 0.7529 - loss: 0.6502 - val_auc_1: 0.7292 - val_loss: 0.6069\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.60553\n",
      "10/10 - 23s - 2s/step - auc_1: 0.7920 - loss: 0.6133 - val_auc_1: 0.7296 - val_loss: 0.6074\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 261ms/step - auc_1: 0.8490 - loss: 0.5284 - val_auc_1: 0.7307 - val_loss: 0.6073\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.60553\n",
      "10/10 - 24s - 2s/step - auc_1: 0.8057 - loss: 0.6135 - val_auc_1: 0.7294 - val_loss: 0.6080\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.60553\n",
      "10/10 - 3s - 297ms/step - auc_1: 0.8135 - loss: 0.6184 - val_auc_1: 0.7296 - val_loss: 0.6078\n",
      "Epoch 48: early stopping\n"
     ]
    }
   ],
   "source": [
    "# implementing early stopping\n",
    "es_tune = EarlyStopping(\n",
    "     monitor='val_loss', \n",
    "     mode='min',  \n",
    "     patience=20, \n",
    "     verbose=1  \n",
    "     )\n",
    "# implementing model checkpoint\n",
    "mc_tune = ModelCheckpoint(\n",
    "      'fine_tuned_house.keras',\n",
    "       monitor='val_loss',\n",
    "       mode='min',\n",
    "       verbose=1, \n",
    "       save_best_only=True\n",
    "      )\n",
    "hist = model_fine_tuned.fit(\n",
    "      x=trainGen,\n",
    "      steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "      validation_data=valGen,\n",
    "      epochs=50,\n",
    "      verbose=2,\n",
    "      callbacks=[es_tune, mc_tune]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6s/step\n",
      "No. of test images 61\n",
      "{'M': 0, 'O': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valGen.reset()\n",
    "velIdxs = model.predict(\n",
    "             x=valGen,\n",
    "             steps=(totalTest // BATCH_SIZE) + 1\n",
    "            )\n",
    "velIdxs = np.argmax(velIdxs, axis = 1)\n",
    "print(\"No. of test images\", len(velIdxs))\n",
    "print(valGen.class_indices)\n",
    "cm = confusion_matrix(valGen.classes, velIdxs)\n",
    "heatmap = sns.heatmap(cm, annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
